{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6tCv-A_bJVb"
   },
   "source": [
    "# Lesson 4: Quantization Theory\n",
    "\n",
    "In this lab, you will perform Linear Quantization.\n",
    "\n",
    "#### Libraries to install\n",
    "- If you are running this notebook on your local machine, you can install the following:\n",
    "\n",
    "```Python\n",
    "!pip install transformers==4.35.0\n",
    "!pip install quanto==0.0.11\n",
    "!pip install torch==2.1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5-FLAN\n",
    "- Please note that due to hardware memory constraints, and in order to offer this course for free to everyone, the code you'll run here is for the T5-FLAN model instead of the EleutherAI AI Pythia model.  \n",
    "- Thank you for your understanding! ü§ó\n",
    "\n",
    "For the T5-FLAN model, here is one more library to install if you are running locally:\n",
    "```Python\n",
    "!pip install sentencepiece==0.2.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: jupyter in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: notebook in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter) (7.4.5)\n",
      "Requirement already satisfied: jupyter-console in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter) (6.30.1)\n",
      "Requirement already satisfied: ipywidgets in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter) (8.1.7)\n",
      "Requirement already satisfied: jupyterlab in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter) (4.4.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (8.37.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (24.2)\n",
      "Requirement already satisfied: psutil>=5.7 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipywidgets->jupyter) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipywidgets->jupyter) (3.0.15)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-console->jupyter) (3.0.52)\n",
      "Requirement already satisfied: pygments in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-console->jupyter) (2.19.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab->jupyter) (75.8.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab->jupyter) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from nbconvert->jupyter) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from nbconvert->jupyter) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from nbconvert->jupyter) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from async-lru>=1.0.0->jupyterlab->jupyter) (4.12.2)\n",
      "Requirement already satisfied: webencodings in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: anyio in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.9.0)\n",
      "Requirement already satisfied: certifi in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
      "Requirement already satisfied: colorama in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-client>=8.0.0->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (311)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.25.1)\n",
      "Requirement already satisfied: requests>=2.31 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.2)\n",
      "Requirement already satisfied: wcwidth in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.27.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: fqdn in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.0)\n",
      "Requirement already satisfied: pycparser in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.23)\n",
      "Requirement already satisfied: lark>=1.2.2 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.2.2)\n",
      "Requirement already satisfied: arrow>=0.15.0 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in d:\\jobrelated\\conda_envs\\llama\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20250822)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "model_name = \"google/flan-t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "height": 92
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "height": 41
   },
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0316,  0.0092, -0.0255,  ...,  0.0726, -0.0743,  0.0248],\n",
      "        [-0.1088,  0.0024,  0.1102,  ...,  0.0702,  0.0320, -0.0037],\n",
      "        [-0.0230, -0.0305,  0.0025,  ...,  0.0196,  0.0333,  0.1948],\n",
      "        ...,\n",
      "        [-0.1560,  0.0096, -0.0963,  ...,  0.0430,  0.1022,  0.0862],\n",
      "        [-0.0767, -0.0164, -0.1109,  ..., -0.0115, -0.0603, -0.0807],\n",
      "        [-0.0468, -0.0603, -0.0261,  ..., -0.0425, -0.0016,  0.0135]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print(model.encoder.block[0])\n",
    "print(model.decoder.block[0].layer[0].SelfAttention.q.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "height": 109
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annie scott\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hello, my name is \"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "height": 75
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model size is 0.307844608 GB\n"
     ]
    }
   ],
   "source": [
    "from helper import compute_module_sizes\n",
    "module_sizes = compute_module_sizes(model)\n",
    "print(f\"The model size is {module_sizes[''] * 1e-9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize the model (8-bit precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from quanto import quantize, freeze, qint8\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "height": 41
   },
   "outputs": [],
   "source": [
    "quantize(model, weights=qint8, activations=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the model\n",
    "- This step takes a bit of memory, and so for the Pythia model that is shown in the lecture video, it will not run in the classroom.\n",
    "- This will work fine with the smaller T5-Flan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "freeze(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QBytesTensor(tensor([[ -19,    6,  -16,  ...,   45,  -46,   15],\n",
      "        [ -79,    2,   80,  ...,   51,   23,   -3],\n",
      "        [ -15,  -20,    2,  ...,   13,   22,  127],\n",
      "        ...,\n",
      "        [-104,    6,  -64,  ...,   29,   68,   57],\n",
      "        [ -38,   -8,  -55,  ...,   -6,  -30,  -40],\n",
      "        [ -30,  -39,  -17,  ...,  -28,   -1,    9]], dtype=torch.int8), scale=tensor([[0.0016],\n",
      "        [0.0014],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0014],\n",
      "        [0.0017],\n",
      "        [0.0016],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0019],\n",
      "        [0.0016],\n",
      "        [0.0013],\n",
      "        [0.0020],\n",
      "        [0.0016],\n",
      "        [0.0015],\n",
      "        [0.0020],\n",
      "        [0.0014],\n",
      "        [0.0013],\n",
      "        [0.0013],\n",
      "        [0.0015],\n",
      "        [0.0012],\n",
      "        [0.0014],\n",
      "        [0.0023],\n",
      "        [0.0014],\n",
      "        [0.0014],\n",
      "        [0.0015],\n",
      "        [0.0013],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0014],\n",
      "        [0.0018],\n",
      "        [0.0014],\n",
      "        [0.0013],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0020],\n",
      "        [0.0014],\n",
      "        [0.0018],\n",
      "        [0.0017],\n",
      "        [0.0013],\n",
      "        [0.0013],\n",
      "        [0.0012],\n",
      "        [0.0012],\n",
      "        [0.0013],\n",
      "        [0.0012],\n",
      "        [0.0015],\n",
      "        [0.0013],\n",
      "        [0.0018],\n",
      "        [0.0013],\n",
      "        [0.0018],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0013],\n",
      "        [0.0015],\n",
      "        [0.0013],\n",
      "        [0.0016],\n",
      "        [0.0017],\n",
      "        [0.0013],\n",
      "        [0.0019],\n",
      "        [0.0016],\n",
      "        [0.0013],\n",
      "        [0.0014],\n",
      "        [0.0010],\n",
      "        [0.0009],\n",
      "        [0.0013],\n",
      "        [0.0013],\n",
      "        [0.0023],\n",
      "        [0.0019],\n",
      "        [0.0016],\n",
      "        [0.0012],\n",
      "        [0.0010],\n",
      "        [0.0012],\n",
      "        [0.0012],\n",
      "        [0.0011],\n",
      "        [0.0015],\n",
      "        [0.0012],\n",
      "        [0.0010],\n",
      "        [0.0025],\n",
      "        [0.0013],\n",
      "        [0.0014],\n",
      "        [0.0009],\n",
      "        [0.0011],\n",
      "        [0.0013],\n",
      "        [0.0016],\n",
      "        [0.0014],\n",
      "        [0.0018],\n",
      "        [0.0010],\n",
      "        [0.0010],\n",
      "        [0.0010],\n",
      "        [0.0013],\n",
      "        [0.0021],\n",
      "        [0.0011],\n",
      "        [0.0019],\n",
      "        [0.0016],\n",
      "        [0.0011],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0012],\n",
      "        [0.0018],\n",
      "        [0.0013],\n",
      "        [0.0011],\n",
      "        [0.0016],\n",
      "        [0.0014],\n",
      "        [0.0011],\n",
      "        [0.0013],\n",
      "        [0.0011],\n",
      "        [0.0011],\n",
      "        [0.0018],\n",
      "        [0.0010],\n",
      "        [0.0015],\n",
      "        [0.0009],\n",
      "        [0.0023],\n",
      "        [0.0019],\n",
      "        [0.0014],\n",
      "        [0.0012],\n",
      "        [0.0014],\n",
      "        [0.0013],\n",
      "        [0.0011],\n",
      "        [0.0010],\n",
      "        [0.0012],\n",
      "        [0.0012],\n",
      "        [0.0010],\n",
      "        [0.0010],\n",
      "        [0.0009],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0021],\n",
      "        [0.0017],\n",
      "        [0.0016],\n",
      "        [0.0014],\n",
      "        [0.0013],\n",
      "        [0.0017],\n",
      "        [0.0019],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0013],\n",
      "        [0.0014],\n",
      "        [0.0019],\n",
      "        [0.0015],\n",
      "        [0.0013],\n",
      "        [0.0015],\n",
      "        [0.0013],\n",
      "        [0.0015],\n",
      "        [0.0017],\n",
      "        [0.0018],\n",
      "        [0.0014],\n",
      "        [0.0016],\n",
      "        [0.0016],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0018],\n",
      "        [0.0014],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0017],\n",
      "        [0.0018],\n",
      "        [0.0014],\n",
      "        [0.0015],\n",
      "        [0.0013],\n",
      "        [0.0015],\n",
      "        [0.0012],\n",
      "        [0.0016],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0016],\n",
      "        [0.0015],\n",
      "        [0.0013],\n",
      "        [0.0019],\n",
      "        [0.0017],\n",
      "        [0.0013],\n",
      "        [0.0016],\n",
      "        [0.0012],\n",
      "        [0.0022],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0016],\n",
      "        [0.0017],\n",
      "        [0.0015],\n",
      "        [0.0020],\n",
      "        [0.0019],\n",
      "        [0.0017],\n",
      "        [0.0014],\n",
      "        [0.0013],\n",
      "        [0.0014],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0014],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0018],\n",
      "        [0.0011],\n",
      "        [0.0026],\n",
      "        [0.0014],\n",
      "        [0.0011],\n",
      "        [0.0013],\n",
      "        [0.0019],\n",
      "        [0.0012],\n",
      "        [0.0014],\n",
      "        [0.0018],\n",
      "        [0.0014],\n",
      "        [0.0016],\n",
      "        [0.0016],\n",
      "        [0.0011],\n",
      "        [0.0012],\n",
      "        [0.0012],\n",
      "        [0.0011],\n",
      "        [0.0012],\n",
      "        [0.0013],\n",
      "        [0.0013],\n",
      "        [0.0011],\n",
      "        [0.0012],\n",
      "        [0.0011],\n",
      "        [0.0014],\n",
      "        [0.0012],\n",
      "        [0.0011],\n",
      "        [0.0012],\n",
      "        [0.0011],\n",
      "        [0.0012],\n",
      "        [0.0016],\n",
      "        [0.0013],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0014],\n",
      "        [0.0014],\n",
      "        [0.0012],\n",
      "        [0.0013],\n",
      "        [0.0018],\n",
      "        [0.0012],\n",
      "        [0.0016],\n",
      "        [0.0015],\n",
      "        [0.0013],\n",
      "        [0.0016],\n",
      "        [0.0018],\n",
      "        [0.0017],\n",
      "        [0.0011],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0014],\n",
      "        [0.0014],\n",
      "        [0.0011],\n",
      "        [0.0013],\n",
      "        [0.0011],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0014],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0013],\n",
      "        [0.0011],\n",
      "        [0.0021],\n",
      "        [0.0012],\n",
      "        [0.0012],\n",
      "        [0.0014],\n",
      "        [0.0012],\n",
      "        [0.0013],\n",
      "        [0.0011],\n",
      "        [0.0013],\n",
      "        [0.0012],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0018],\n",
      "        [0.0023],\n",
      "        [0.0010],\n",
      "        [0.0021],\n",
      "        [0.0014],\n",
      "        [0.0010],\n",
      "        [0.0016],\n",
      "        [0.0016],\n",
      "        [0.0013],\n",
      "        [0.0015],\n",
      "        [0.0012],\n",
      "        [0.0013],\n",
      "        [0.0012],\n",
      "        [0.0015],\n",
      "        [0.0019],\n",
      "        [0.0016],\n",
      "        [0.0023],\n",
      "        [0.0012],\n",
      "        [0.0012],\n",
      "        [0.0012],\n",
      "        [0.0014],\n",
      "        [0.0019],\n",
      "        [0.0012],\n",
      "        [0.0011],\n",
      "        [0.0016],\n",
      "        [0.0016],\n",
      "        [0.0015],\n",
      "        [0.0010],\n",
      "        [0.0020],\n",
      "        [0.0019],\n",
      "        [0.0013],\n",
      "        [0.0014],\n",
      "        [0.0015],\n",
      "        [0.0019],\n",
      "        [0.0012],\n",
      "        [0.0009],\n",
      "        [0.0013],\n",
      "        [0.0013],\n",
      "        [0.0010],\n",
      "        [0.0009],\n",
      "        [0.0016],\n",
      "        [0.0019],\n",
      "        [0.0012],\n",
      "        [0.0016],\n",
      "        [0.0017],\n",
      "        [0.0009],\n",
      "        [0.0014],\n",
      "        [0.0015],\n",
      "        [0.0009],\n",
      "        [0.0017],\n",
      "        [0.0014],\n",
      "        [0.0019],\n",
      "        [0.0014],\n",
      "        [0.0036],\n",
      "        [0.0013],\n",
      "        [0.0010],\n",
      "        [0.0010],\n",
      "        [0.0016],\n",
      "        [0.0017],\n",
      "        [0.0015],\n",
      "        [0.0018],\n",
      "        [0.0015],\n",
      "        [0.0024],\n",
      "        [0.0015],\n",
      "        [0.0018],\n",
      "        [0.0014],\n",
      "        [0.0016],\n",
      "        [0.0014],\n",
      "        [0.0016],\n",
      "        [0.0013],\n",
      "        [0.0019],\n",
      "        [0.0015],\n",
      "        [0.0018],\n",
      "        [0.0014],\n",
      "        [0.0016],\n",
      "        [0.0025],\n",
      "        [0.0017],\n",
      "        [0.0014],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0014],\n",
      "        [0.0019],\n",
      "        [0.0017],\n",
      "        [0.0018],\n",
      "        [0.0016],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0017],\n",
      "        [0.0015],\n",
      "        [0.0017],\n",
      "        [0.0016],\n",
      "        [0.0017],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0020],\n",
      "        [0.0019],\n",
      "        [0.0027],\n",
      "        [0.0025],\n",
      "        [0.0017],\n",
      "        [0.0017],\n",
      "        [0.0017],\n",
      "        [0.0015],\n",
      "        [0.0021],\n",
      "        [0.0018],\n",
      "        [0.0019],\n",
      "        [0.0017],\n",
      "        [0.0023],\n",
      "        [0.0016],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0014],\n",
      "        [0.0017],\n",
      "        [0.0018],\n",
      "        [0.0017],\n",
      "        [0.0015],\n",
      "        [0.0019],\n",
      "        [0.0015],\n",
      "        [0.0015],\n",
      "        [0.0020],\n",
      "        [0.0015]]), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# print(model.encoder.block[0])\n",
    "print(model.decoder.block[0].layer[0].SelfAttention.q.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "height": 58
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model size is 0.12682868 GB\n"
     ]
    }
   ],
   "source": [
    "module_sizes = compute_module_sizes(model)\n",
    "print(f\"The model size is {module_sizes[''] * 1e-9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try running inference on the quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "height": 109
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annie scott\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hello, my name is \"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqmyZYGbbO8A"
   },
   "source": [
    "## Note: Quantizing the model used in the lecture video will not work due to classroom hardware limitations.\n",
    "- Here is the code that Marc, the instructor is walking through.  \n",
    "- It will likely run on your local computer if you have 8GB of memory, which is usually the minimum for personal computers.\n",
    "  - To run locally, you can download the notebook and the helper.py file by clicking on the \"Jupyter icon\" at the top of the notebook and navigating the file directory of this classroom.  Also download the requirements.txt to install all the required libraries.\n",
    "\n",
    "### Without Quantization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load [EleutherAI/pythia-410m](https://huggingface.co/EleutherAI/pythia-410m) model and tokenizer.\n",
    "\n",
    "```Python\n",
    "from transformers import AutoModelForCausalLM\n",
    "model_name = \"EleutherAI/pythia-410m\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             low_cpu_mem_usage=True)\n",
    "print(model.gpt_neox)\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a start of a (`text`) sentence which you'd like the model to complete.\n",
    "```Python\n",
    "text = \"Hello my name is\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "outputs\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the model's size using the helper function, `compute_module_sizes`.\n",
    "```Python\n",
    "from helper import compute_module_sizes\n",
    "module_sizes = compute_module_sizes(model)\n",
    "print(f\"The model size is {module_sizes[''] * 1e-9} GB\")\n",
    "print(model.gpt_neox.layers[0].attention.dense.weight)\n",
    "```\n",
    "**Note:** The weights are in `fp32`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BC809CYugOp"
   },
   "source": [
    "### 8-bit Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from quanto import quantize, freeze\n",
    "import torch\n",
    "\n",
    "quantize(model, weights=torch.int8, activations=None)\n",
    "# after performing quantization\n",
    "print(model.gpt_neox)\n",
    "print(model.gpt_neox.layers[0].attention.dense.weight)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The \"freeze\" function requires more memory than is available in this classroom.\n",
    "- This code will run on a machine that has 8GB of memory, and so it will likely work if you run this code on your local machine.\n",
    "\n",
    "```Python\n",
    "# freeze the model\n",
    "freeze(model)\n",
    "print(model.gpt_neox.layers[0].attention.dense.weight)\n",
    "\n",
    "# get model size after quantization\n",
    "module_sizes = compute_module_sizes(model)\n",
    "print(f\"The model size is {module_sizes[''] * 1e-9} GB\")\n",
    "\n",
    "# run inference after quantizing the model\n",
    "outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing \"linear quantization\" to \"downcasting\"\n",
    "\n",
    "To recap the difference between the \"linear quantization\" method in this lesson with the \"downcasting\" method in the previous lesson:\n",
    "\n",
    "- When downcasting a model, you convert the model's parameters to a more compact data type (bfloat16).  During inference, the model performs its calculations in this data type, and its activations are in this data type.  Downcasting may work with the bfloat16 data type, but the model performance will likely degrade with any smaller data type, and won't work if you convert to an integer data type (like the int8 in this lesson).\n",
    "\n",
    "\n",
    "- In this lesson, you used another quantization method, \"linear quantization\", which enables the quantized model to maintain performance much closer to the original model by converting from the compressed data type back to the original FP32 data type during inference. So when the model makes a prediction, it is performing the matrix multiplications in FP32, and the activations are in FP32.  This enables you to quantize the model in data types smaller than bfloat16, such as int8, in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is just the beginning...\n",
    "- This course is intended to be a beginner-friendly introduction to the field of quantization. üê£\n",
    "- If you'd like to learn more about quantization, please stay tuned for another Hugging Face short course that goes into more depth on this topic (launching in a few weeks!) ü§ó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did you like this course?\n",
    "\n",
    "- If you liked this course, could you consider giving a rating and share what you liked? üíï\n",
    "- If you did not like this course, could you also please share what you think could have made it better? üôè\n",
    "\n",
    "#### A note about the \"Course Review\" page.\n",
    "The rating options are from 0 to 10.\n",
    "- A score of 9 or 10 means you like the course.ü§ó\n",
    "- A score of 7 or 8 means you feel neutral about the course (neither like nor dislike).üôÑ\n",
    "- A score of 0,1,2,3,4,5 or 6 all mean that you do not like the course. üò≠\n",
    "  - Whether you give a 0 or a 6, these are all defined as \"detractors\" according to the standard measurement called \"Net Promoter Score\". üßê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpTGuZzDRr5A8ocSoYIFkP",
   "collapsed_sections": [
    "4V_amrl-xG9D",
    "dODA6rR0z297"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
